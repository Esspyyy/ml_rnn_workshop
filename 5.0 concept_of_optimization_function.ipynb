{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Best for Last: Understanding Optimization Functions!\n",
    "\n",
    "You've just learned about **backpropagation**, which helps us calculate how much each weight in the neural network contributed to the error. Now, the big question is: **what do we do with this information ?** This is where **optimization functions** come into play."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## What is an Optimization Function?\n",
    "\n",
    "Optimization functions take the results from backpropagation and use them to adjust the networkâ€™s weights in a way that reduces the overall error. By carefully tweaking the weights, optimization functions guide the learning process and help the neural network make better predictions over time. The first step in this optimization process is understanding **Gradient Descent**.\n",
    "\n",
    "### Gradient Descent\n",
    "\n",
    "Gradient Descent is a fundamental optimization algorithm used to minimize the loss function. The key idea behind Gradient Descent is to use the gradient of the loss function to update the weights, moving in the direction that reduces the loss. This process is repeated iteratively until the model reaches the lowest possible error.\n",
    "\n",
    "### Mathematical Explanation of Gradient Descent\n",
    "\n",
    "In Gradient Descent, weights are updated iteratively using the following rule:\n",
    "\n",
    "$$\n",
    "w = w - \\eta \\cdot \\nabla L(w)\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "- **\\( w \\)** represents the current weights of the model.\n",
    "- **\\( \\delta \\)** is the learning rate, a small positive number that controls the size of the weight update step.\n",
    "- **\\( \\nabla L(w) \\)** is the gradient of the loss function \\( L \\) with respect to the weights \\( w \\). This gradient indicates the direction in which the weights need to be adjusted to minimize the loss.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.youtube.com/watch?v=mdKjMPmcWjY (End at 3:30min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "For now we are gonna see where gradients are manipulated and how they took effect :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "input = np.array([1.0, 2.0, 3.0, 4.0])\n",
    "target = np.array([2.0, 3.0, 4.0, 5.0])\n",
    "\n",
    "W1 = np.array([[1.5, 1.3, 1.8, 1.1],\n",
    "              [1.5, 1.3, 1.8, 1.1],\n",
    "              [1.5, 1.3, 1.8, 1.1],\n",
    "              [1.5, 1.3, 1.8, 1.1]]) # weights for the input layer that are randomly initialized for 1 example\n",
    "\n",
    "prediction = input @ W1\n",
    "\n",
    "loss = np.mean((prediction - target) ** 2) # mean squared error\n",
    "print(\"loss\", loss)\n",
    "\n",
    "G1 = 2 * np.mean((prediction - target) * input) # gradient of the loss function\n",
    "print(\"gradient\", G1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a gradient let's try to minimize the loss **below 1.30**, try your best !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo update the weights with the gradient\n",
    "\n",
    "New_W1 = W1 + 0.0001 * G1\n",
    "\n",
    "prediction = New_W1 @ input\n",
    "loss = np.mean((prediction - target) ** 2)\n",
    "print(\"new loss\", loss) # should be smaller than the previous loss\n",
    "\n",
    "W1 = New_W1\n",
    "# Don't hesitate to run the code multiple times to see the loss decreasing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "As you can see, you didn't directly manipulate the gradient;\n",
    "instead, you adjusted the weights by adding or subtracting a certain percentage of it, known as the learning rate. But how is this process done automatically? This is where the concept of gradient descent comes into play:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch implement the optimization in this way :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "learning_rate = 0.01\n",
    "gradien_descent = torch.optim.SGD(params=..., lr=learning_rate) # params should be the weights of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic Adjustment in Gradient Descent\n",
    "\n",
    "With Gradient Descent, the process of adjusting the weights is both simple and efficient. Here's how it works automatically:\n",
    "\n",
    "1. **Following the Gradient's Lead**: The gradient points in the direction of the steepest increase in loss. By taking the negative gradient, we move in the direction that most rapidly decreases the loss. This adjustment is inherently built into the Gradient Descent update rule:\n",
    "\n",
    "    $$\n",
    "    w = w - \\eta \\cdot \\nabla L(w)\n",
    "    $$\n",
    "\n",
    "    The negative sign ensures that the weights move in the opposite direction of the gradient, towards minimizing the loss.\n",
    "\n",
    "2. **Dynamic Adjustment**: As the model learns, the gradient changes. A large positive gradient means the loss will increase if the weight is increased, so the weight is reduced. A large negative gradient means the loss will decrease if the weight is increased, so the weight is increased.\n",
    "\n",
    "3. **Role of the Learning Rate**: The learning rate (\\( \\eta \\)) controls the step size of each adjustment. It helps fine-tune the balance between moving quickly toward lower loss values and making sure we don't overshoot the optimal point. A small learning rate results in small steps, making fine-tuned adjustments, while a larger learning rate allows for bigger changes.\n",
    "\n",
    "4. **Automatic Decision-Making**: Gradient Descent doesn't need to explicitly decide to add or subtract from the weights because the gradient and the learning rate inherently dictate the adjustment. The mathematical formulation ensures that each step taken is in the direction that will reduce the loss. This method is called the **step()**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great job making it this far! An important key point to remember is that when we loop through the training process, we need to reset the gradient values at the start of each loop. This is necessary because gradients must be recalculated with each new loss computation to reflect the most recent state of the model. This is done using the method called **zero_grad()**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
